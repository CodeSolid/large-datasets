{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df20ed7-eb0b-4649-9fd4-5a0720bf38da",
   "metadata": {},
   "source": [
    "# Large Data Sets in Python\n",
    "\n",
    "This is the companion source for the article [Large Data Sets in Python: Pandas and the Alternatives](https://codesolid.com/large-data-sets-in-python-pandas-and-the-alternatives/).  Note that this Notebook relies on the [Riiid Test Answer Prediction Data Set](https://www.kaggle.com/c/riiid-test-answer-prediction), which you'll need to download and unzip into the ./data directory.\n",
    "\n",
    "The sections in this Notebook don't exactly match the sequence of the article, because we we've tried to keep similar tools together.  So here we'll run some operations in Pandas first, then Dask, then Polars. Note that the file size of train.db is large (about 5.4 Gb), so keep in mind:\n",
    "\n",
    "* You'll need a machine with enough memory.  At least 16 Gb is recommended.\n",
    "* You might periodically restart the kernel (Kernel / Restart Kernel from the menu) to free up memory, though since we re-use the \"df\" object, this isn't strictly necessary.\n",
    "\n",
    "## Important:\n",
    "\n",
    "This notebook compares several techniques that take time to execute.  Some of these cells will take 30-35 seconds or more to run so please be patient; others are significantly faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaa4f86-d894-46e4-b884-b0cbf00a9ab2",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "***\n",
    "Reading from a CSV file into memory, no types specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89a2eab4-e9e7-4a54-9891-38f86d4aad57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pandas plain read_csv]\n",
      "Elapsed time: 36.61 seconds\n"
     ]
    }
   ],
   "source": [
    "from timer import Timer\n",
    "import pandas as pd\n",
    "df = None\n",
    "with Timer(\"Pandas plain read_csv\"):\n",
    "    df = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37e877-61b0-41ae-bc80-cd71b1db6d52",
   "metadata": {},
   "source": [
    "***\n",
    "Reading from a CSV file into memory, specifying types in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5873ae3f-3cc1-4066-8eea-07730a992fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Read csv using polars]\n",
      "Elapsed time: 37.31 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from timer import Timer\n",
    "import numpy as np\n",
    "\n",
    "dtypes = {\n",
    "'row_id': np.int64,\n",
    " 'timestamp': np.int32, \n",
    " 'user_id': np.int32, \n",
    " 'content_id': np.int32, \n",
    " 'content_type_id': np.int32,\n",
    "'task_container_id': np.int32, \n",
    "'user_answer': np.int32, \n",
    "'answered_correctly': np.int32,\n",
    "'prior_question_elapsed_time': np.float64, \n",
    "'prior_question_had_explanation': object\n",
    "}\n",
    "\n",
    "with Timer(\"Read csv using polars\"):\n",
    "    df = pd.read_csv(\"data/train.csv\", dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67837cf-b0d1-4785-b489-543ae5741b2f",
   "metadata": {},
   "source": [
    "***\n",
    "Set an index and fetch rows once in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e96ad573-e081-43c5-ac45-1d538c4be516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pandas set_index]\n",
      "Elapsed time: 3.99 seconds\n",
      "[Fetchs]\n",
      "Elapsed time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"Pandas set_index\"):\n",
    "    df.set_index(\"user_id\")\n",
    "\n",
    "with Timer(\"Fetchs\"):\n",
    "    rows = df.loc[40828]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa642b80-eb8e-4f13-8e7b-cc244a1c8eb7",
   "metadata": {},
   "source": [
    "***\n",
    "# Dask\n",
    "\n",
    "Read the CSV file and set an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "246171c3-0762-4b4c-9a89-0f45fe1e3115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dask read_csv]\n",
      "Elapsed time: 0.58 seconds\n",
      "[set_index.csv]\n",
      "Elapsed time: 33.08 seconds\n"
     ]
    }
   ],
   "source": [
    "from dask import dataframe\n",
    "from timer import Timer\n",
    "\n",
    "import numpy as np\n",
    "dtypes = {\n",
    "'row_id': np.int64,\n",
    " 'timestamp': np.int32, \n",
    " 'user_id': np.int32, \n",
    " 'content_id': np.int32, \n",
    " 'content_type_id': np.int32,\n",
    "'task_container_id': np.int32, \n",
    "'user_answer': np.int32, \n",
    "'answered_correctly': np.int32,\n",
    "'prior_question_elapsed_time': np.float64, \n",
    "'prior_question_had_explanation': object\n",
    "}\n",
    "\n",
    "with Timer(\"dask read_csv\"):\n",
    "    df = dataframe.read_csv(\"data/train.csv\", low_memory=False)\n",
    "    \n",
    "with Timer(\"set_index.csv\"):\n",
    "    df = df.set_index(\"user_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5248c4e7-ea7b-497a-b5ed-6141915f8707",
   "metadata": {},
   "source": [
    "***\n",
    "Select a set of rows with the index set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74bd37f-03f3-4bd3-93a3-bb535f35c771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Get rows for user_id 40828]\n",
      "Elapsed time: 30.31 seconds\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"Get rows for user_id 40828\"):\n",
    "    rows = df.loc[40828].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d50810-36ad-42d5-a1a2-b1c7be37f9bf",
   "metadata": {},
   "source": [
    "***\n",
    "# Polars (Full Read -- Non-Lazy)\n",
    "\n",
    "Read whole CSV in memory in Polars and select rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0633576-6b9e-46ed-986e-74f83cab68e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Read CSV into memory using Polars]\n",
      "Elapsed time: 13.99 seconds\n",
      "[Select rows in memory, polars]\n",
      "Elapsed time: 0.18 seconds\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "with Timer(\"Read CSV into memory using Polars\"):\n",
    "    df = pl.read_csv(\"data/train.csv\")\n",
    "\n",
    "with Timer(\"Select rows in memory, polars\"):\n",
    "    rows = df.filter(pl.col('user_id') == 2147470777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3f371a-47f3-4c56-9fe5-2b55b0ccd499",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Polars and Pandas using Parquet\n",
    "\n",
    "Use Polars to read file (CSV) and write it back out to Parquet.  We later read it back in using Pandas.  The next two cells should be run in order.  The first one will take the longest, but it sets things up for better performance in the second cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45b9f370-6c81-44a2-aede-cc637de1a1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Read CSV in Polars]\n",
      "Elapsed time: 15.97 seconds\n",
      "[Write to Parquet in Polars]\n",
      "Elapsed time: 18.97 seconds\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "from timer import Timer\n",
    "\n",
    "with Timer(\"Read CSV in Polars\"):\n",
    "    df = pl.read_csv(\"data/train.csv\")\n",
    "\n",
    "with Timer(\"Write to Parquet in Polars\"):\n",
    "    df.write_parquet(\"data/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0be9ced-98ef-4ead-94e4-ef0ce5199a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Time to read from parquet in Pandas]\n",
      "Elapsed time: 7.36 seconds\n",
      "[Time to read from parquet in Polars]\n",
      "Elapsed time: 5.38 seconds\n"
     ]
    }
   ],
   "source": [
    "# Read from Parquet in Polars and Pandas\n",
    "df = None\n",
    "with Timer(\"Time to read from parquet in Pandas\"):\n",
    "    df = pd.read_parquet(\"data/train.parquet\")\n",
    "\n",
    "df = None\n",
    "with Timer(\"Time to read from parquet in Polars\"):\n",
    "    df = pl.read_parquet(\"data/train.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970ae42-82b7-47a3-8566-30e8b02631f3",
   "metadata": {},
   "source": [
    "***\n",
    "# Polars Lazy Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bf7b560-9c8e-48d4-89bf-4cc5aa9367cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Scan CSV for early user (Polars)]\n",
      "Elapsed time: 3.64 seconds\n",
      "[Read CSV for later user (Polars)]\n",
      "Elapsed time: 3.52 seconds\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from timer import Timer \n",
    "\n",
    "with Timer(\"Scan CSV for early user (Polars)\"):\n",
    "    df = pl.scan_csv(\"data/train.csv\").filter(pl.col('user_id') == 40828).collect()\n",
    "\n",
    "with Timer(\"Read CSV for later user (Polars)\"):\n",
    "    df = pl.scan_csv(\"data/train.csv\").filter(pl.col('user_id') == 2147470777).collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
